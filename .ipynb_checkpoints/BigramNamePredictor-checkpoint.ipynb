{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59527d71-60bc-47cf-b726-c435a71f1653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0251feb-f7d3-4b72-8e4a-ed1aa7d929b4",
   "metadata": {},
   "source": [
    "# Import Text Document of Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c79af6a9-ff83-4ca3-98e0-d9ba6cb19dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r', encoding=\"utf-8\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8f3670-c95d-402a-a472-dc9ac1c9859e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513bb5ff-17cb-48e1-89ff-931038791bcf",
   "metadata": {},
   "source": [
    "### Create training set of bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c53ecb5a-99b8-4363-b7da-2961966d17e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0 #denotes the beginning and ending of words\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074bc13a-4802-4883-b208-4d6aa1f6ec94",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be7126d-7ea6-4458-8802-d3612c80bc53",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs, ys = [], [] #x = input, y = target\n",
    "\n",
    "for w in words:\n",
    "    chars = ['.'] + list (w) + ['.']\n",
    "    for char1, char2 in zip(chars, chars[1:]):\n",
    "        index1 = stoi[char1]\n",
    "        index2 = stoi[char2]\n",
    "        xs.append(index1)\n",
    "        ys.append(index2)\n",
    "\n",
    "        \n",
    "#conver to tensors\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)        \n",
    "num = xs.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5969c5fc-42da-4e52-acc9-00c246bcc227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 228146\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of examples: {num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523f062-0ad6-4515-91cf-4c932c69be10",
   "metadata": {},
   "source": [
    "### Initialize Generator for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb9fd83a-00e0-499a-83b9-fadaaab58bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27,27), generator=g, requires_grad=True) #generate 27 x 27 vectors of random weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b7bd9-bcf3-4df3-a7d1-0ef41ba3a753",
   "metadata": {},
   "source": [
    "## Optimizaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58e8ce6c-4c89-4e7c-8df8-d655166d79d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.758953809738159\n",
      "3.3710803985595703\n",
      "3.1540329456329346\n",
      "3.0203664302825928\n",
      "2.9277069568634033\n",
      "2.8604001998901367\n",
      "2.809727430343628\n",
      "2.7701010704040527\n",
      "2.738072633743286\n",
      "2.711496114730835\n",
      "2.6890032291412354\n",
      "2.6696887016296387\n",
      "2.6529300212860107\n",
      "2.638277053833008\n",
      "2.6253879070281982\n",
      "2.613990545272827\n",
      "2.60386323928833\n",
      "2.5948219299316406\n",
      "2.586712121963501\n",
      "2.57940411567688\n",
      "2.572789192199707\n",
      "2.5667765140533447\n",
      "2.5612881183624268\n",
      "2.5562589168548584\n",
      "2.551633834838867\n",
      "2.547366142272949\n",
      "2.5434155464172363\n",
      "2.5397486686706543\n",
      "2.536336660385132\n",
      "2.5331544876098633\n",
      "2.5301806926727295\n",
      "2.5273966789245605\n",
      "2.5247862339019775\n",
      "2.522334575653076\n",
      "2.520029067993164\n",
      "2.5178580284118652\n",
      "2.515810489654541\n",
      "2.513878345489502\n",
      "2.512052059173584\n",
      "2.510324001312256\n",
      "2.5086872577667236\n",
      "2.5071346759796143\n",
      "2.5056614875793457\n",
      "2.504261016845703\n",
      "2.502929210662842\n",
      "2.5016613006591797\n",
      "2.5004522800445557\n",
      "2.4992990493774414\n",
      "2.498197317123413\n",
      "2.497144937515259\n",
      "2.496137857437134\n",
      "2.495173692703247\n",
      "2.4942495822906494\n",
      "2.493363380432129\n",
      "2.4925124645233154\n",
      "2.4916954040527344\n",
      "2.4909098148345947\n",
      "2.4901537895202637\n",
      "2.4894261360168457\n",
      "2.488725185394287\n",
      "2.488049268722534\n",
      "2.4873974323272705\n",
      "2.4867680072784424\n",
      "2.4861602783203125\n",
      "2.4855728149414062\n",
      "2.4850046634674072\n",
      "2.4844553470611572\n",
      "2.4839234352111816\n",
      "2.483408212661743\n",
      "2.4829084873199463\n",
      "2.482424259185791\n",
      "2.48195481300354\n",
      "2.481499195098877\n",
      "2.4810571670532227\n",
      "2.4806275367736816\n",
      "2.480210065841675\n",
      "2.479804515838623\n",
      "2.479410409927368\n",
      "2.4790265560150146\n",
      "2.4786534309387207\n",
      "2.4782907962799072\n",
      "2.4779369831085205\n",
      "2.4775924682617188\n",
      "2.477257251739502\n",
      "2.4769303798675537\n",
      "2.476611375808716\n",
      "2.4763011932373047\n",
      "2.4759981632232666\n",
      "2.4757025241851807\n",
      "2.475414276123047\n",
      "2.475132703781128\n",
      "2.474858045578003\n",
      "2.4745900630950928\n",
      "2.474327564239502\n",
      "2.474071741104126\n",
      "2.4738218784332275\n",
      "2.4735772609710693\n",
      "2.4733383655548096\n",
      "2.47310471534729\n",
      "2.4728758335113525\n"
     ]
    }
   ],
   "source": [
    "for k in range(100): #epochs\n",
    "    #forward pass\n",
    "    x_encoding = F.one_hot(xs, num_classes=27).float() #for each character (index), create a 1d array of length 27 \n",
    "                                                       #(26 letters + special start/end char) where the chars index is 1 while all else is 0\n",
    "    logits = (x_encoding @ W) #  log counts #matrix multiplication sign in pytorch, the resulting 5,27 tensor tells us the firing rate of each neuron given these 5 examples\n",
    "    counts = logits.exp() # better approximation of counts because always positive\n",
    "    probs = counts / counts.sum(1, keepdim=True) # normalize to approximate individual probabilities for each letter in the vector. counts into probs is called softmax\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() # negative log likelihood\n",
    "    print(loss.item())\n",
    "    \n",
    "    #backward pass\n",
    "    W.grad = None # set the zero to gradient\n",
    "    loss.backward() # fills in intermediary gradients all the way back to W\n",
    "    \n",
    "    #update weights\n",
    "    W.data += -50 * W.grad   # each element here describes the effect on the loss function in the form of 27x27 tensor\n",
    "                        # essentially setting the learning rate to -.1 (which is negative to minimize loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89dd0a66-2335-468c-8949-ef7bc4a4772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mor.\n",
      "axwaninaymoryles.\n",
      "kondmaisah.\n",
      "anchshizarie.\n",
      "odaren.\n",
      "iaddash.\n",
      "h.\n",
      "jionatien.\n",
      "egwver.\n",
      "ga.\n",
      "t.\n",
      "a.\n",
      "jayn.\n",
      "ilemannariaenien.\n",
      "ad.\n",
      "f.\n",
      "akiinela.\n",
      "trttanakerorudayaaxetona.\n",
      "lamoyonutonadengin.\n",
      "torrederahmokallovwiprasskh.\n",
      "a.\n",
      "wai.\n",
      "kn.\n",
      "jaieendenelfff.\n",
      "kianu.\n",
      "eryly.\n",
      "zeeieil.\n",
      "kayxtrglynenn.\n",
      "r.\n",
      "t.\n",
      "rja.\n",
      "kronanuroliojanidames.\n",
      "dikie.\n",
      "s.\n",
      "elarieiavelvalllaish.\n",
      "eythann.\n",
      "janianaeri.\n",
      "boma.\n",
      "poree.\n",
      "l.\n",
      "adhanoena.\n",
      "naisaryan.\n",
      "sialaitalyee.\n",
      "cena.\n",
      "lisarr.\n",
      "bizyngor.\n",
      "eve.\n",
      "blahish.\n",
      "tovih.\n",
      "al.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(50):\n",
    "    output = []\n",
    "    index = 0\n",
    "    while True:\n",
    "        x_encoding = F.one_hot(torch.tensor([index]), num_classes=27).float()\n",
    "        logits = x_encoding @ W # predict log counts\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdims=True)\n",
    "        #------------------------\n",
    "        index = torch.multinomial(probs, num_samples=1,replacement=True, generator=g).item()\n",
    "        output.append(itos[index])\n",
    "        if index == 0:\n",
    "            break\n",
    "    print(''.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c5fc40c9-84d9-421a-81ad-47168623c613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97646cf3-b3df-497d-ae69-b85d68710249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
