{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "59527d71-60bc-47cf-b726-c435a71f1653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0251feb-f7d3-4b72-8e4a-ed1aa7d929b4",
   "metadata": {},
   "source": [
    "# Import Text Document of Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c79af6a9-ff83-4ca3-98e0-d9ba6cb19dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r', encoding=\"utf-8\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9b8f3670-c95d-402a-a472-dc9ac1c9859e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513bb5ff-17cb-48e1-89ff-931038791bcf",
   "metadata": {},
   "source": [
    "### Create training set of bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c53ecb5a-99b8-4363-b7da-2961966d17e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0 #denotes the beginning and ending of words\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "074bc13a-4802-4883-b208-4d6aa1f6ec94",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7be7126d-7ea6-4458-8802-d3612c80bc53",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs, ys = [], [] #x = input, y = target\n",
    "\n",
    "for w in words:\n",
    "    chars = ['.'] + list (w) + ['.']\n",
    "    for char1, char2 in zip(chars, chars[1:]):\n",
    "        index1 = stoi[char1]\n",
    "        index2 = stoi[char2]\n",
    "        xs.append(index1)\n",
    "        ys.append(index2)\n",
    "\n",
    "        \n",
    "#conver to tensors\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)        \n",
    "num = xs.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5969c5fc-42da-4e52-acc9-00c246bcc227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 228146\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of examples: {num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523f062-0ad6-4515-91cf-4c932c69be10",
   "metadata": {},
   "source": [
    "### Initialize Generator for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bb9fd83a-00e0-499a-83b9-fadaaab58bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27,27), generator=g, requires_grad=True) #generate 27 x 27 vectors of random weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b7bd9-bcf3-4df3-a7d1-0ef41ba3a753",
   "metadata": {},
   "source": [
    "## Optimizaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "58e8ce6c-4c89-4e7c-8df8-d655166d79d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4726526737213135\n",
      "2.4724342823028564\n",
      "2.4722204208374023\n",
      "2.472010850906372\n",
      "2.471806049346924\n",
      "2.4716053009033203\n",
      "2.471409320831299\n",
      "2.4712166786193848\n",
      "2.4710280895233154\n",
      "2.470843553543091\n",
      "2.4706625938415527\n",
      "2.4704854488372803\n",
      "2.4703118801116943\n",
      "2.4701414108276367\n",
      "2.4699742794036865\n",
      "2.469810724258423\n",
      "2.4696500301361084\n",
      "2.469492197036743\n",
      "2.4693379402160645\n",
      "2.4691860675811768\n",
      "2.4690372943878174\n",
      "2.468891143798828\n",
      "2.468747615814209\n",
      "2.46860671043396\n",
      "2.468468427658081\n",
      "2.468332529067993\n",
      "2.4681990146636963\n",
      "2.4680681228637695\n",
      "2.4679393768310547\n",
      "2.467813014984131\n",
      "2.467688798904419\n",
      "2.4675662517547607\n",
      "2.4674465656280518\n",
      "2.4673283100128174\n",
      "2.467212438583374\n",
      "2.467097759246826\n",
      "2.4669857025146484\n",
      "2.4668750762939453\n",
      "2.466766595840454\n",
      "2.4666597843170166\n",
      "2.4665544033050537\n",
      "2.4664509296417236\n",
      "2.4663493633270264\n",
      "2.4662492275238037\n",
      "2.4661502838134766\n",
      "2.466053009033203\n",
      "2.4659576416015625\n",
      "2.4658634662628174\n",
      "2.465770721435547\n",
      "2.465679407119751\n",
      "2.4655895233154297\n",
      "2.465500593185425\n",
      "2.4654133319854736\n",
      "2.465327501296997\n",
      "2.465242624282837\n",
      "2.4651591777801514\n",
      "2.4650766849517822\n",
      "2.4649956226348877\n",
      "2.4649152755737305\n",
      "2.464836597442627\n",
      "2.46475887298584\n",
      "2.46468186378479\n",
      "2.464606523513794\n",
      "2.464531660079956\n",
      "2.4644579887390137\n",
      "2.464385747909546\n",
      "2.4643139839172363\n",
      "2.464243173599243\n",
      "2.4641737937927246\n",
      "2.4641048908233643\n",
      "2.4640369415283203\n",
      "2.4639699459075928\n",
      "2.4639036655426025\n",
      "2.4638383388519287\n",
      "2.4637739658355713\n",
      "2.463710308074951\n",
      "2.4636473655700684\n",
      "2.463585376739502\n",
      "2.4635238647460938\n",
      "2.463463544845581\n",
      "2.4634037017822266\n",
      "2.4633448123931885\n",
      "2.4632863998413086\n",
      "2.463228940963745\n",
      "2.46317195892334\n",
      "2.4631154537200928\n",
      "2.463060140609741\n",
      "2.4630050659179688\n",
      "2.4629504680633545\n",
      "2.4628970623016357\n",
      "2.462843894958496\n",
      "2.462791681289673\n",
      "2.462739944458008\n",
      "2.462688446044922\n",
      "2.4626376628875732\n",
      "2.462587594985962\n",
      "2.462538242340088\n",
      "2.462489128112793\n",
      "2.4624407291412354\n",
      "2.462392807006836\n"
     ]
    }
   ],
   "source": [
    "for k in range(100): #epochs\n",
    "    #forward pass\n",
    "    x_encoding = F.one_hot(xs, num_classes=27).float() #for each character (index), create a 1d array of length 27 \n",
    "                                                       #(26 letters + special start/end char) where the chars index is 1 while all else is 0\n",
    "    logits = (x_encoding @ W) #  log counts #matrix multiplication sign in pytorch, the resulting 5,27 tensor tells us the firing rate of each neuron given these 5 examples\n",
    "    counts = logits.exp() # better approximation of counts because always positive\n",
    "    probs = counts / counts.sum(1, keepdim=True) # normalize to approximate individual probabilities for each letter in the vector. counts into probs is called softmax\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() # negative log likelihood\n",
    "    print(loss.item())\n",
    "    \n",
    "    #backward pass\n",
    "    W.grad = None # set the zero to gradient\n",
    "    loss.backward() # fills in intermediary gradients all the way back to W\n",
    "    \n",
    "    #update weights\n",
    "    W.data += -50 * W.grad   # each element here describes the effect on the loss function in the form of 27x27 tensor\n",
    "                        # essentially setting the learning rate to -.1 (which is negative to minimize loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "89dd0a66-2335-468c-8949-ef7bc4a4772b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c5fc40c9-84d9-421a-81ad-47168623c613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97646cf3-b3df-497d-ae69-b85d68710249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
